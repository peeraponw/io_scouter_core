{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b800179eb936>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "# import emoji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label (0:คนปกติ, 1:io)</th>\n",
       "      <th>language</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>...</th>\n",
       "      <th>quote_url</th>\n",
       "      <th>video</th>\n",
       "      <th>geo</th>\n",
       "      <th>near</th>\n",
       "      <th>source</th>\n",
       "      <th>time_update</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.162571e+18</td>\n",
       "      <td>1.162571e+18</td>\n",
       "      <td>@zeeill บ้านเมืองเดือดร้อนวุ่นวายขนาดนี้ ไม่ให...</td>\n",
       "      <td>1</td>\n",
       "      <td>th</td>\n",
       "      <td>1.162341e+18</td>\n",
       "      <td>2019-08-17 10:45:59 SE Asia Standard Time</td>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>10:45:59</td>\n",
       "      <td>700</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1603127298878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>บ้านเมืองเดือดร้อน</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.251352e+18</td>\n",
       "      <td>1.251352e+18</td>\n",
       "      <td>@nomi_nee เห็นด้วยคะ ดีมาก เวลาบ้านเมืองเดือดร...</td>\n",
       "      <td>1</td>\n",
       "      <td>th</td>\n",
       "      <td>1.251134e+18</td>\n",
       "      <td>2020-04-18 10:27:51 SE Asia Standard Time</td>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>10:27:51</td>\n",
       "      <td>700</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1603127276312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>บ้านเมืองเดือดร้อน</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.045623e+18</td>\n",
       "      <td>1.045623e+18</td>\n",
       "      <td>@DeFirenze พวกจาบจ้วงสถาบันก็เช่นกัน</td>\n",
       "      <td>1</td>\n",
       "      <td>th</td>\n",
       "      <td>1.045621e+18</td>\n",
       "      <td>2018-09-28 17:33:59 SE Asia Standard Time</td>\n",
       "      <td>2018-09-28</td>\n",
       "      <td>17:33:59</td>\n",
       "      <td>700</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1603128157824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>จาบจ้วงสถาบัน</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.293108e+18</td>\n",
       "      <td>1.293108e+18</td>\n",
       "      <td>“สุดารัตน์” ไม่เห็นด้วยจาบจ้วงสถาบัน  https://...</td>\n",
       "      <td>0</td>\n",
       "      <td>th</td>\n",
       "      <td>1.293108e+18</td>\n",
       "      <td>2020-08-11 15:50:28 SE Asia Standard Time</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>15:50:28</td>\n",
       "      <td>700</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1603129947131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>จาบจ้วงสถาบัน</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.293148e+18</td>\n",
       "      <td>1.293148e+18</td>\n",
       "      <td>@Sulovebossss ป้าหน่อยออกมาประกาศเพื่อไทยไม่สน...</td>\n",
       "      <td>1</td>\n",
       "      <td>th</td>\n",
       "      <td>1.293144e+18</td>\n",
       "      <td>2020-08-11 18:30:47 SE Asia Standard Time</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>18:30:47</td>\n",
       "      <td>700</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1603127380825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>จาบจ้วงสถาบัน</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id        id_str  \\\n",
       "0  1.162571e+18  1.162571e+18   \n",
       "1  1.251352e+18  1.251352e+18   \n",
       "2  1.045623e+18  1.045623e+18   \n",
       "3  1.293108e+18  1.293108e+18   \n",
       "4  1.293148e+18  1.293148e+18   \n",
       "\n",
       "                                               tweet  label (0:คนปกติ, 1:io)  \\\n",
       "0  @zeeill บ้านเมืองเดือดร้อนวุ่นวายขนาดนี้ ไม่ให...                       1   \n",
       "1  @nomi_nee เห็นด้วยคะ ดีมาก เวลาบ้านเมืองเดือดร...                       1   \n",
       "2               @DeFirenze พวกจาบจ้วงสถาบันก็เช่นกัน                       1   \n",
       "3  “สุดารัตน์” ไม่เห็นด้วยจาบจ้วงสถาบัน  https://...                       0   \n",
       "4  @Sulovebossss ป้าหน่อยออกมาประกาศเพื่อไทยไม่สน...                       1   \n",
       "\n",
       "  language  conversation_id                                 created_at  \\\n",
       "0       th     1.162341e+18  2019-08-17 10:45:59 SE Asia Standard Time   \n",
       "1       th     1.251134e+18  2020-04-18 10:27:51 SE Asia Standard Time   \n",
       "2       th     1.045621e+18  2018-09-28 17:33:59 SE Asia Standard Time   \n",
       "3       th     1.293108e+18  2020-08-11 15:50:28 SE Asia Standard Time   \n",
       "4       th     1.293144e+18  2020-08-11 18:30:47 SE Asia Standard Time   \n",
       "\n",
       "         date      time  timezone  ...  quote_url  video  geo  near  source  \\\n",
       "0  2019-08-17  10:45:59       700  ...        NaN      0  NaN   NaN     NaN   \n",
       "1  2020-04-18  10:27:51       700  ...        NaN      0  NaN   NaN     NaN   \n",
       "2  2018-09-28  17:33:59       700  ...        NaN      0  NaN   NaN     NaN   \n",
       "3  2020-08-11  15:50:28       700  ...        NaN      0  NaN   NaN     NaN   \n",
       "4  2020-08-11  18:30:47       700  ...        NaN      0  NaN   NaN     NaN   \n",
       "\n",
       "     time_update translate trans_src trans_dest             keyword  \n",
       "0  1603127298878       NaN       NaN        NaN  บ้านเมืองเดือดร้อน  \n",
       "1  1603127276312       NaN       NaN        NaN  บ้านเมืองเดือดร้อน  \n",
       "2  1603128157824       NaN       NaN        NaN       จาบจ้วงสถาบัน  \n",
       "3  1603129947131       NaN       NaN        NaN       จาบจ้วงสถาบัน  \n",
       "4  1603127380825       NaN       NaN        NaN       จาบจ้วงสถาบัน  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/twitter_quotes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = df['tweet']\n",
    "label = df['label (0:คนปกติ, 1:io)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mention(text):\n",
    "    output = re.sub(\"@[A-Za-zก-๏0-9_]+\",\"\", text)\n",
    "    return output\n",
    "def remove_link(text):\n",
    "    output = re.sub(r'https?:\\/\\/\\S*', \"\", text, flags=re.MULTILINE)\n",
    "    return output\n",
    "def remove_punctuation(text):\n",
    "    output = re.sub('[^a-z0-9ก-๏] ', \"\", text)\n",
    "    return output\n",
    "def remove_space(text):\n",
    "    text = text.strip()\n",
    "    output = re.sub(\"[\\s+]\", '', text)\n",
    "    return output\n",
    "def preprocess(text):\n",
    "    text = remove_mention(text)\n",
    "    text = remove_link(text)\n",
    "    text = remove_punctuation(text)\n",
    "#     text = remove_space(text)\n",
    "    return text\n",
    "\n",
    "# idx = 34\n",
    "# print(tweet[idx])\n",
    "# print(remove_link(tweet[idx]))\n",
    "# print(remove_mention(tweet[idx]))\n",
    "# print(preprocess(tweet[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       บ้านเมือง|เดือดร้อน|วุ่นวาย|ขนาด|นี้|ไม่|ให้กำ...\n",
       "1       เห็นด้วย|คะ|ดีมาก|เวลา|บ้านเมือง|เดือดร้อน|ต้อ...\n",
       "2                           พวก|จาบจ้วง|สถาบัน|ก็|เช่นกัน\n",
       "3             “|สุดา|รัตน์|ไม่เห็นด้วย|จาบจ้วง|สถาบัน|via\n",
       "4       ป้า|หน่อย|ออกมา|ประกาศ|เพื่อ|ไทย|ไม่|สนับสนุน|...\n",
       "                              ...                        \n",
       "5197    เล่า|จริงๆ|ครับ|เล่า|แบบ|ไร้|หลักฐาน|รองรับ|ด้...\n",
       "5198    fy|ผม|ไม่ได้|รัก|ร.|10|ครับ|แต่|ก็|ยัง|ไม่ได้|...\n",
       "5199    ตอนนี้|ผม|ก็|ไม่ได้|ศรัทธา|ราชวงศ์|นะ|คือ|ไม่ไ...\n",
       "5200    บางที|ผม|ก็|สงสาร|ร.|10|นะ|โฆษณา|ผลงาน|ก็|โดน|...\n",
       "5201    ชอบ|บท|สัมภาษณ์|ของ|ร.|10|เมื่อ|ครั้ง|ทรง|เป็น...\n",
       "Name: tweet, Length: 5202, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp import word_tokenize\n",
    "from tqdm import tqdm_notebook\n",
    "from pythainlp.ulmfit import process_thai\n",
    "\n",
    "# remove mention, links, and punctuations before processing\n",
    "tweet = tweet.map(lambda x: preprocess(x))\n",
    "# process tweet as default of thaipynlp\n",
    "tweet = tweet.map(lambda x: \"|\".join(process_thai(x))) # processed tweets\n",
    "wc = tweet.map(lambda x: len(x.split(\"|\"))) # word counts\n",
    "uwc = tweet.map(lambda x: len(set(x.split(\"|\")))) # unique word counts\n",
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4161,), (1041,), (4161,), (1041,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(tweet, label, test_size=0.2, random_state=1412)\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9151646238884883, 0.930835734870317)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean(), y_valid.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4161, 2364), (1041, 2364))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=process_thai, ngram_range=(1,2), min_df=20, sublinear_tf=True)\n",
    "tfidf_fit = tfidf.fit(X_train)\n",
    "text_train = tfidf_fit.transform(X_train)\n",
    "text_valid = tfidf_fit.transform(X_valid)\n",
    "text_train.shape, text_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9337175792507204"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit logistic regression models\n",
    "model = LogisticRegression(C=2., penalty=\"l2\", solver=\"liblinear\", dual=False, multi_class=\"ovr\")\n",
    "model.fit(text_train.toarray(),y_train)\n",
    "preds = model.predict(text_valid.toarray())\n",
    "score = model.score(text_valid.toarray(),y_valid)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9337175792507204\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(y_valid, preds)\n",
    "print(score)\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\",\n",
    "            xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ULMFit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ongoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "# from fastai.callbacks import CSVLogger, SaveModelCallback\n",
    "from pythainlp.ulmfit import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-967aee4af084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mThaiTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"th\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_rules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_rules_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_rules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_rules_th\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m processor = [TokenizeProcessor(tokenizer=tt, chunksize=10000, mark_fields=False),\n\u001b[1;32m      3\u001b[0m             NumericalizeProcessor(vocab=None, max_vocab=60000, min_freq=2)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tt = Tokenizer(tok_func=ThaiTokenizer, lang=\"th\", pre_rules=pre_rules_th, post_rules=post_rules_th)\n",
    "processor = [TokenizeProcessor(tokenizer=tt, chunksize=10000, mark_fields=False),\n",
    "            NumericalizeProcessor(vocab=None, max_vocab=60000, min_freq=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT attempt -> not yet worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "\n",
    "print('Using Tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_encode(texts, tokenizer, maxlen=512):\n",
    "    enc_di = tokenizer.batch_encode_plus(\n",
    "             texts, \n",
    "             return_attention_masks=False, \n",
    "             return_token_type_ids=False,\n",
    "             pad_to_max_length=True,\n",
    "             max_length=maxlen)\n",
    "    \n",
    "    return np.array(enc_di['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(transformer, max_len=512):\n",
    "    \n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    out = Dense(5, activation='softmax')(cls_token) # 5 ratings to predict\n",
    "    \n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 16 \n",
    "MODEL = 'jplu/tf-xlm-roberta-large' # bert-base-multilingual-uncased\n",
    "# MODEL = 'albert-xxlarge-v2' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(tweet,\n",
    "                                                  label,\n",
    "                                                  stratify=label,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=2020)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 192\n",
    "\n",
    "X_train = regular_encode(X_train.values, tokenizer, maxlen=MAX_LEN)\n",
    "X_val = regular_encode(X_val.values, tokenizer, maxlen=MAX_LEN)\n",
    "# X_test = regular_encode(test_df['review'].values, word_tokenizer, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_train, y_train))\n",
    "    .repeat()\n",
    "    .shuffle(1024)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_val, y_val))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(X_test)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
