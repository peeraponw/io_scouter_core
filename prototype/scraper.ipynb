{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tweepy\n",
    "from configparser import ConfigParser\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read('../twitterAPI.cfg')\n",
    "\n",
    "consumer_key = config['consumer']['key']\n",
    "consumer_secret = config['consumer']['secret']\n",
    "\n",
    "access_token = config['access']['key']\n",
    "access_token_secret = config['access']['secret']\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def scraper_users(username, label, count):\n",
    "    for user in username:\n",
    "        try:     \n",
    "            # Creation of query method using parameters\n",
    "            tweets = tweepy.Cursor(api.user_timeline,id=user).items(count)\n",
    "\n",
    "            # Pulling information from tweets iterable object\n",
    "            tweets_list = [{\"created_at\": tweet.created_at,\n",
    "                            \"tweet_id\": tweet.id, \n",
    "                            \"text\": tweet.text} for tweet in tweets]\n",
    "\n",
    "        except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            time.sleep(3)\n",
    "        # check if this user has already been scraped\n",
    "        filepath = os.path.join(label, user+'.csv')\n",
    "        if os.path.isfile(filepath):\n",
    "            # read old file and append\n",
    "            old_df = pd.read_csv(filepath)\n",
    "            new_df = pd.DataFrame(tweets_list, columns=['created_at', 'tweet_id', 'text'])\n",
    "            df = pd.concat([old_df, new_df]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        else:\n",
    "            # Creation of dataframe from tweets list\n",
    "            # Add or remove columns as you remove tweet information\n",
    "            df = pd.DataFrame(tweets_list, columns=['created_at', 'tweet_id', 'text'])\n",
    "        df.to_csv(filepath, index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = ['topazine','moui',\n",
    "'joe_black317',\n",
    "'pakapong_report',\n",
    "'fookkub',\n",
    "'AmaratJeab',\n",
    "'wirojlak',\n",
    "'JakkritTomTom',\n",
    "'iconnnz',\n",
    "'jomquan',\n",
    "'sirotek',\n",
    "'bkksnow',\n",
    "'kovitw1',\n",
    "'BadDlRECTOR',\n",
    "'NetiwitC',\n",
    "'HRLAthai',\n",
    "'arnonnampa',\n",
    "'WasanaWW',\n",
    "'taopiphop',\n",
    "'charoenpura',\n",
    "'Piyabutr_FWP',\n",
    "'johnwinyu',\n",
    "'charoenpura',\n",
    "'jomquan',\n",
    "'WassanaNanuam',\n",
    "'PravitR',\n",
    "'kamphaka',\n",
    "'DrArunee_Ying',\n",
    "'jamornvivat',\n",
    "'geekjuggler',\n",
    "'tpagon',\n",
    "'KomsakAddams',\n",
    "'joshuawongcf',\n",
    "'purple_cottonn',\n",
    "'pingvachir',\n",
    "'Bossskuno',\n",
    "'ud_awat',\n",
    "'biggbiggyabc',\n",
    "'Sawarinni',\n",
    "'peartunwarat',\n",
    "'merlinx26',\n",
    "'stitch_pololo',\n",
    "'worawisut',\n",
    "'macroart',\n",
    "'noppatjak',\n",
    "'suthichai',\n",
    "'Kitti3Miti',\n",
    "'thapanee3miti',\n",
    "'magicbelle__',\n",
    "'Psolemn',\n",
    "'priwpriww',\n",
    "'PlobJai']\n",
    "label = \"0\"\n",
    "\n",
    "scraper_users(username, label, 50)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   created_at  50 non-null     datetime64[ns]\n",
      " 1   tweet_id    50 non-null     int64         \n",
      " 2   text        50 non-null     object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0\\\\PlobJai.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
